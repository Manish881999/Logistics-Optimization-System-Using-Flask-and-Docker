{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a40a7e-16d0-4180-a713-65ea35a65b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502d6954-a8ab-4e9a-a70e-b16d10e9c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas sqlalchemy pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5011f5e1-9bf3-4ab1-92f0-ecfb52d516eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas scikit-learn sqlalchemy pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eb30599-b47b-4db9-a1e4-7697165c5ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ortools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c82759-d32c-4902-96e9-b9534bb05999",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b8518df-e482-432d-bee8-df6a1409ece7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 1000 rows into `traffic_data` table.\n",
      "Inserted 1000 rows into `weather_data` table.\n"
     ]
    }
   ],
   "source": [
    "import pymysql\n",
    "import random\n",
    "\n",
    "# Connect to MySQL\n",
    "connection = pymysql.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"root\",\n",
    "    database=\"translogi\"\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Function to insert mock traffic data\n",
    "def populate_traffic_data():\n",
    "    origins = [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\"]\n",
    "    destinations = [\"Miami\", \"San Francisco\", \"Dallas\", \"Atlanta\", \"Seattle\"]\n",
    "    durations = [\"2 hours 15 mins\", \"3 hours 30 mins\", \"5 hours 10 mins\", \"1 hour 45 mins\", \"4 hours 20 mins\"]\n",
    "\n",
    "    for _ in range(1000):\n",
    "        origin = random.choice(origins)\n",
    "        destination = random.choice(destinations)\n",
    "        duration = random.choice(durations)\n",
    "\n",
    "        query = \"INSERT INTO traffic_data (origin, destination, duration) VALUES (%s, %s, %s)\"\n",
    "        values = (origin, destination, duration)\n",
    "        cursor.execute(query, values)\n",
    "\n",
    "    connection.commit()\n",
    "    print(\"Inserted 1000 rows into `traffic_data` table.\")\n",
    "\n",
    "# Function to insert mock weather data\n",
    "def populate_weather_data():\n",
    "    cities = [\"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\"]\n",
    "    weather_conditions = [\"clear sky\", \"rain\", \"cloudy\", \"snow\", \"thunderstorm\"]\n",
    "    temperatures = [298.15, 300.15, 295.15, 310.15, 285.15]  # Temperatures in Kelvin\n",
    "\n",
    "    for _ in range(1000):\n",
    "        city = random.choice(cities)\n",
    "        weather = random.choice(weather_conditions)\n",
    "        temperature = random.choice(temperatures)\n",
    "\n",
    "        query = \"INSERT INTO weather_data (city, weather, temperature) VALUES (%s, %s, %s)\"\n",
    "        values = (city, weather, temperature)\n",
    "        cursor.execute(query, values)\n",
    "\n",
    "    connection.commit()\n",
    "    print(\"Inserted 1000 rows into `weather_data` table.\")\n",
    "\n",
    "# Populate the tables\n",
    "populate_traffic_data()\n",
    "populate_weather_data()\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f50a1e4-9ab5-475b-bd04-00daeccc7f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e8eef8b-8e8f-4f05-adbd-f7dd3a37cca0",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5bb680b-5174-4de6-9390-992092c3b92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to table `avg_delivery_time_by_area`\n",
      "Processed data saved to table `combined_data`\n",
      "Data engineering pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "\n",
    "# Connect to the MySQL database using SQLAlchemy\n",
    "db_engine = create_engine(\"mysql+pymysql://root:root@localhost/translogi\")\n",
    "\n",
    "# Function to load data from the database\n",
    "def load_data_from_db():\n",
    "    # Load traffic data\n",
    "    traffic_data = pd.read_sql(\"SELECT * FROM traffic_data\", con=db_engine)\n",
    "    # Load weather data\n",
    "    weather_data = pd.read_sql(\"SELECT * FROM weather_data\", con=db_engine)\n",
    "    return traffic_data, weather_data\n",
    "\n",
    "# Function to preprocess traffic data\n",
    "def preprocess_traffic_data(df):\n",
    "    # Handle missing values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Extract numeric duration in minutes from text (e.g., \"5 hours 30 mins\")\n",
    "    def extract_duration(text):\n",
    "        \"\"\"\n",
    "        Extract duration in minutes from a string like \"5 hours 30 mins\" or \"45 mins\".\n",
    "        Handles invalid or unexpected formats gracefully.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if \"hour\" in text:\n",
    "                parts = text.split(\"hour\")\n",
    "                hours = int(parts[0].strip())\n",
    "                if \"min\" in parts[1]:\n",
    "                    minutes = int(parts[1].split(\"min\")[0].strip())\n",
    "                else:\n",
    "                    minutes = 0\n",
    "                return hours * 60 + minutes\n",
    "            elif \"min\" in text:\n",
    "                return int(text.split(\"min\")[0].strip())\n",
    "            else:\n",
    "                return 0  # Default to 0 if no valid format is found\n",
    "        except (ValueError, IndexError, AttributeError) as e:\n",
    "            print(f\"Error parsing duration: {text} - {e}\")\n",
    "            return 0  # Default to 0 in case of error\n",
    "\n",
    "    df[\"duration\"] = df[\"duration\"].str.replace(\"hours\", \"hour\").str.replace(\"mins\", \"min\")\n",
    "    df[\"duration_minutes\"] = df[\"duration\"].apply(extract_duration)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to preprocess weather data\n",
    "def preprocess_weather_data(df):\n",
    "    # Handle missing values\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Convert temperature from Kelvin to Celsius\n",
    "    df[\"temperature_celsius\"] = df[\"temperature\"] - 273.15\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to create derived features\n",
    "def generate_features(traffic_data, weather_data):\n",
    "    # Example feature: Average delivery time by area\n",
    "    traffic_data[\"area\"] = traffic_data[\"origin\"]  # Assuming origin as area\n",
    "    avg_delivery_time_by_area = traffic_data.groupby(\"area\")[\"duration_minutes\"].mean().reset_index()\n",
    "    avg_delivery_time_by_area.rename(columns={\"duration_minutes\": \"avg_delivery_time\"}, inplace=True)\n",
    "\n",
    "    # Merge traffic and weather data for combined analysis\n",
    "    combined_data = pd.merge(\n",
    "        traffic_data, weather_data, left_on=\"origin\", right_on=\"city\", how=\"inner\"\n",
    "    )\n",
    "\n",
    "    # Feature: Impact of weather on delivery time\n",
    "    combined_data[\"weather_impact\"] = np.where(\n",
    "        combined_data[\"weather\"].str.contains(\"rain|snow|storm\", case=False, na=False), 1, 0\n",
    "    )\n",
    "\n",
    "    # Feature: Vehicle capacity utilization (mock data)\n",
    "    combined_data[\"vehicle_utilization\"] = np.random.uniform(0.5, 1.0, len(combined_data))\n",
    "\n",
    "    return avg_delivery_time_by_area, combined_data\n",
    "\n",
    "# Save processed data back to the database\n",
    "def save_processed_data(df, table_name):\n",
    "    df.to_sql(table_name, con=db_engine, if_exists=\"replace\", index=False)\n",
    "    print(f\"Processed data saved to table `{table_name}`\")\n",
    "\n",
    "# Main processing pipeline\n",
    "def main():\n",
    "    # Step 1: Load raw data\n",
    "    traffic_data, weather_data = load_data_from_db()\n",
    "\n",
    "    # Step 2: Preprocess raw data\n",
    "    traffic_data = preprocess_traffic_data(traffic_data)\n",
    "    weather_data = preprocess_weather_data(weather_data)\n",
    "\n",
    "    # Step 3: Generate derived features\n",
    "    avg_delivery_time_by_area, combined_data = generate_features(traffic_data, weather_data)\n",
    "\n",
    "    # Step 4: Save processed data back to the database\n",
    "    save_processed_data(avg_delivery_time_by_area, \"avg_delivery_time_by_area\")\n",
    "    save_processed_data(combined_data, \"combined_data\")\n",
    "\n",
    "    print(\"Data engineering pipeline completed successfully!\")\n",
    "\n",
    "# Run the pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db6d65f-94f3-4b73-915f-0661d3f91362",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad50a157-0c2d-4ed2-80bb-f041ff1b2b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Mean Squared Error: 7545.96\n",
      "R^2 Score: -0.31\n",
      "Model saved to delivery_time_model.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from joblib import dump\n",
    "\n",
    "# Connect to the MySQL database\n",
    "db_engine = create_engine(\"mysql+pymysql://root:root@localhost/translogi\")\n",
    "\n",
    "# Load processed data from the database\n",
    "def load_data():\n",
    "    query = \"SELECT * FROM combined_data\"\n",
    "    data = pd.read_sql(query, con=db_engine)\n",
    "    return data\n",
    "\n",
    "# Preprocess data for modeling\n",
    "def preprocess_for_modeling(data):\n",
    "    # Use only 30% of the data\n",
    "    data = data.sample(frac=0.2, random_state=42)\n",
    "\n",
    "    # Select relevant features and the target variable\n",
    "    features = data[[\"vehicle_utilization\", \"temperature_celsius\", \"weather_impact\"]]\n",
    "    target = data[\"duration_minutes\"]\n",
    "\n",
    "    return features, target\n",
    "\n",
    "# Train and evaluate the model\n",
    "def train_model(features, target):\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train a Random Forest Regressor\n",
    "    model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Model Performance:\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    print(f\"R^2 Score: {r2:.2f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Save the trained model to a file\n",
    "def save_model(model, filename=\"delivery_time_model.joblib\"):\n",
    "    dump(model, filename)\n",
    "    print(f\"Model saved to {filename}\")\n",
    "\n",
    "# Main pipeline for training the model\n",
    "def main():\n",
    "    # Step 1: Load data\n",
    "    data = load_data()\n",
    "\n",
    "    # Step 2: Preprocess data for modeling\n",
    "    features, target = preprocess_for_modeling(data)\n",
    "\n",
    "    # Step 3: Train the model\n",
    "    model = train_model(features, target)\n",
    "\n",
    "    # Step 4: Save the trained model\n",
    "    save_model(model)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a78c7f-ecfd-4084-af71-1bc214dc2d57",
   "metadata": {},
   "source": [
    "# Route Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e703f3f-9a57-4b6a-b7b0-8439986d1021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route for Vehicle 0: [0, 3, 0]\n",
      "Route for Vehicle 1: [0, 2, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "from ortools.constraint_solver import pywrapcp, routing_enums_pb2\n",
    "import numpy as np\n",
    "\n",
    "# Example data for delivery locations, vehicle capacity, and demand\n",
    "def create_data_model():\n",
    "    \"\"\"Creates the data for the VRP.\"\"\"\n",
    "    data = {}\n",
    "    # Distance matrix (symmetric example)\n",
    "    data['distance_matrix'] = [\n",
    "        [0, 29, 20, 21],\n",
    "        [29, 0, 15, 17],\n",
    "        [20, 15, 0, 28],\n",
    "        [21, 17, 28, 0],\n",
    "    ]\n",
    "    # Delivery demands at each location (including the depot)\n",
    "    data['demands'] = [0, 1, 1, 2]\n",
    "    # Vehicle capacities\n",
    "    data['vehicle_capacities'] = [3, 3]\n",
    "    # Number of vehicles\n",
    "    data['num_vehicles'] = 2\n",
    "    # Depot (starting point for all vehicles)\n",
    "    data['depot'] = 0\n",
    "    return data\n",
    "\n",
    "# Solve the VRP\n",
    "def solve_vrp(data):\n",
    "    \"\"\"Solves the VRP with the given data.\"\"\"\n",
    "    # Create the routing index manager\n",
    "    manager = pywrapcp.RoutingIndexManager(\n",
    "        len(data['distance_matrix']), data['num_vehicles'], data['depot']\n",
    "    )\n",
    "\n",
    "    # Create the Routing Model\n",
    "    routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "    # Define the distance callback\n",
    "    def distance_callback(from_index, to_index):\n",
    "        \"\"\"Returns the distance between two nodes.\"\"\"\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        to_node = manager.IndexToNode(to_index)\n",
    "        return data['distance_matrix'][from_node][to_node]\n",
    "\n",
    "    transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n",
    "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
    "\n",
    "    # Add capacity constraints\n",
    "    def demand_callback(from_index):\n",
    "        \"\"\"Returns the demand at a given node.\"\"\"\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        return data['demands'][from_node]\n",
    "\n",
    "    demand_callback_index = routing.RegisterUnaryTransitCallback(demand_callback)\n",
    "    routing.AddDimensionWithVehicleCapacity(\n",
    "        demand_callback_index,\n",
    "        0,  # Null capacity slack\n",
    "        data['vehicle_capacities'],  # Vehicle maximum capacities\n",
    "        True,  # Start cumul to zero\n",
    "        \"Capacity\"\n",
    "    )\n",
    "\n",
    "    # Define search parameters\n",
    "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "    search_parameters.first_solution_strategy = (\n",
    "        routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)\n",
    "\n",
    "    # Solve the problem\n",
    "    solution = routing.SolveWithParameters(search_parameters)\n",
    "\n",
    "    # Process the solution\n",
    "    if solution:\n",
    "        return get_solution(manager, routing, solution)\n",
    "    else:\n",
    "        print(\"No solution found!\")\n",
    "        return None\n",
    "\n",
    "# Get solution details\n",
    "def get_solution(manager, routing, solution):\n",
    "    \"\"\"Extracts the solution details.\"\"\"\n",
    "    routes = []\n",
    "    for vehicle_id in range(manager.GetNumberOfVehicles()):\n",
    "        index = routing.Start(vehicle_id)\n",
    "        route = []\n",
    "        while not routing.IsEnd(index):\n",
    "            route.append(manager.IndexToNode(index))\n",
    "            index = solution.Value(routing.NextVar(index))\n",
    "        route.append(manager.IndexToNode(index))\n",
    "        routes.append(route)\n",
    "    return routes\n",
    "\n",
    "# Main function to run the optimization\n",
    "def main():\n",
    "    # Step 1: Create data model\n",
    "    data = create_data_model()\n",
    "\n",
    "    # Step 2: Solve VRP\n",
    "    optimized_routes = solve_vrp(data)\n",
    "\n",
    "    # Step 3: Display results\n",
    "    if optimized_routes:\n",
    "        for vehicle_id, route in enumerate(optimized_routes):\n",
    "            print(f\"Route for Vehicle {vehicle_id}: {route}\")\n",
    "    else:\n",
    "        print(\"No routes found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cec8d5-3b96-46e4-a720-e0d6420b3cb6",
   "metadata": {},
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c49be2-96a1-4496-ac38-93fa590b3a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from ortools.constraint_solver import pywrapcp, routing_enums_pb2\n",
    "\n",
    "# Flask app initialization\n",
    "app = Flask(__name__, template_folder=\"templates\", static_folder=\"static\")\n",
    "\n",
    "# Load pre-trained prediction model\n",
    "MODEL_FILE = \"delivery_time_model.joblib\"\n",
    "try:\n",
    "    model = load(MODEL_FILE)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    model = None\n",
    "\n",
    "# Route for serving the dashboard\n",
    "@app.route(\"/\")\n",
    "def dashboard():\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "# Predict delivery time API\n",
    "@app.route(\"/api/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.json\n",
    "        if not data:\n",
    "            return jsonify({\"error\": \"No input data provided\"}), 400\n",
    "\n",
    "        # Extract and validate features\n",
    "        vehicle_utilization = data.get(\"vehicle_utilization\")\n",
    "        temperature_celsius = data.get(\"temperature_celsius\")\n",
    "        weather_impact = data.get(\"weather_impact\")\n",
    "\n",
    "        if None in [vehicle_utilization, temperature_celsius, weather_impact]:\n",
    "            return jsonify({\"error\": \"Missing one or more input fields\"}), 400\n",
    "\n",
    "        features = np.array([[vehicle_utilization, temperature_celsius, weather_impact]])\n",
    "        prediction = model.predict(features)\n",
    "        return jsonify({\"predicted_delivery_time\": prediction[0]})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in /api/predict: {e}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "# Solve VRP API\n",
    "@app.route(\"/api/optimize_routes\", methods=[\"POST\"])\n",
    "def optimize_routes():\n",
    "    try:\n",
    "        data = request.json\n",
    "        if not data:\n",
    "            return jsonify({\"error\": \"No input data provided\"}), 400\n",
    "\n",
    "        manager = pywrapcp.RoutingIndexManager(\n",
    "            len(data['distance_matrix']), data['num_vehicles'], data['depot']\n",
    "        )\n",
    "        routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "        def distance_callback(from_index, to_index):\n",
    "            from_node = manager.IndexToNode(from_index)\n",
    "            to_node = manager.IndexToNode(to_index)\n",
    "            return data['distance_matrix'][from_node][to_node]\n",
    "\n",
    "        transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n",
    "        routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
    "\n",
    "        def demand_callback(from_index):\n",
    "            from_node = manager.IndexToNode(from_index)\n",
    "            return data['demands'][from_node]\n",
    "\n",
    "        demand_callback_index = routing.RegisterUnaryTransitCallback(demand_callback)\n",
    "        routing.AddDimensionWithVehicleCapacity(\n",
    "            demand_callback_index,\n",
    "            0,\n",
    "            data['vehicle_capacities'],\n",
    "            True,\n",
    "            \"Capacity\"\n",
    "        )\n",
    "\n",
    "        search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "        search_parameters.first_solution_strategy = (\n",
    "            routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)\n",
    "\n",
    "        solution = routing.SolveWithParameters(search_parameters)\n",
    "        if not solution:\n",
    "            return jsonify({\"error\": \"No solution found\"}), 404\n",
    "\n",
    "        routes = []\n",
    "        for vehicle_id in range(manager.GetNumberOfVehicles()):\n",
    "            index = routing.Start(vehicle_id)\n",
    "            route = []\n",
    "            while not routing.IsEnd(index):\n",
    "                route.append(manager.IndexToNode(index))\n",
    "                index = solution.Value(routing.NextVar(index))\n",
    "            route.append(manager.IndexToNode(index))\n",
    "            routes.append(route)\n",
    "\n",
    "        return jsonify({\"routes\": routes})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in /api/optimize_routes: {e}\")\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "# Run Flask app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55572ef0-5d22-4a17-9342-06ed4a555afc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
